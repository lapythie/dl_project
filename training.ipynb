{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import random\n",
    "import youtokentome as yttm\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "from notGPT.model import Config, GPT, GPTDataset\n",
    "from notGPT.train import train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config()\n",
    "config.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('GPT_project.zip', 'r') as zipObj:\n",
    "    zipObj.extractall()\n",
    "    \n",
    "data_path = \"tmp.txt\"\n",
    "tokenizer_path = \"pretrained_bpe.model\"\n",
    "\n",
    "# # uncomment to train BPE model from scratch\n",
    "# yttm.BPE.train(data=data_path, model=tokenizer_path,\n",
    "#                vocab_size=config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁W', 'uzz', 'up', '▁Beelzebub']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = yttm.BPE(model=tokenizer_path)\n",
    "tokenizer.encode(\"Wuzzup Beelzebub\", output_type=yttm.OutputType.SUBWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, \"r\", encoding=\"utf-8\") as file_obj:\n",
    "    data = tokenizer.encode(file_obj.read(), bos=False, eos=False,output_type=yttm.OutputType.ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5685, 56853991)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_start_index = int(len(data)*0.0001)\n",
    "validation_start_index, len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 1/100 of tokens\n",
    "train_dataset = GPTDataset(data[:validation_start_index*100], config)\n",
    "# last 1/10_000 of tokens\n",
    "validation_dataset = GPTDataset(data[-validation_start_index:], config)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=config.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available(): device = torch.device('cuda')\n",
    "else: device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (embed): Embedding(40000, 768)\n",
       "  (emb_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (decoder): Sequential(\n",
       "    (0): Decoder(\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (project): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (activation): GELU()\n",
       "        (make_it_bigger): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (make_it_smaller): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Decoder(\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (project): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (activation): GELU()\n",
       "        (make_it_bigger): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (make_it_smaller): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Decoder(\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (project): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (activation): GELU()\n",
       "        (make_it_bigger): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (make_it_smaller): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Decoder(\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (project): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (activation): GELU()\n",
       "        (make_it_bigger): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (make_it_smaller): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Decoder(\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (project): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (activation): GELU()\n",
       "        (make_it_bigger): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (make_it_smaller): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Decoder(\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (project): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (activation): GELU()\n",
       "        (make_it_bigger): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (make_it_smaller): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Decoder(\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (project): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (activation): GELU()\n",
       "        (make_it_bigger): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (make_it_smaller): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Decoder(\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (project): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (activation): GELU()\n",
       "        (make_it_bigger): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (make_it_smaller): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Decoder(\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (project): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (activation): GELU()\n",
       "        (make_it_bigger): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (make_it_smaller): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Decoder(\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (project): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (activation): GELU()\n",
       "        (make_it_bigger): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (make_it_smaller): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Decoder(\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (project): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (activation): GELU()\n",
       "        (make_it_bigger): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (make_it_smaller): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Decoder(\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (project): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (activation): GELU()\n",
       "        (make_it_bigger): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (make_it_smaller): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Linear(in_features=768, out_features=40000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT(config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество обучаемых параметров в сети: 146,889,216\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Количество обучаемых параметров в сети: {count_parameters(model):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=2.5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  73%|███████▎  | 102953/141997 [9:43:38<3:43:58,  2.91it/s, loss=0.0597, perplexity=1.06]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a312ec8c867d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_epoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mepoch_train_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mepoch_val_losses\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4a990056aa25>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, criterion, optimizer, last_n_losses, verbose)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs             = 2\n",
    "\n",
    "train_losses       = []\n",
    "val_losses         = []\n",
    "\n",
    "\n",
    "train_perplexities = []\n",
    "val_perplexities   = []\n",
    "\n",
    "best_val_loss      = float(\"inf\")\n",
    "\n",
    "for n_epoch in range(1, epochs + 1):\n",
    "\n",
    "    epoch_train_losses = train(model, train_loader, criterion, optimizer)\n",
    "    epoch_val_losses   = evaluate(model, validation_loader, criterion)\n",
    "\n",
    "    mean_train_loss    = np.mean(epoch_train_losses)\n",
    "    mean_val_loss      = np.mean(epoch_val_losses)\n",
    "\n",
    "    train_losses.append(epoch_train_losses)\n",
    "    train_perplexities.append(np.exp(mean_train_loss))\n",
    "\n",
    "    val_losses.append(epoch_val_losses)\n",
    "    val_perplexities.append(np.exp(mean_val_loss))\n",
    "\n",
    "    message = f\"Epoch: {n_epoch}\\n\"\n",
    "    message += f\"Train: loss - {mean_train_loss:.4f} | perplexity - {train_perplexities[-1]:.3f}\\n\"\n",
    "    message += f\"Validation: loss - {mean_val_loss: .4f} | perplexity - {val_perplexities[-1]:.3f}\"\n",
    "\n",
    "    print(message)\n",
    "\n",
    "    if mean_val_loss < best_val_loss:\n",
    "\n",
    "        best_val_loss = mean_val_loss\n",
    "\n",
    "        torch.save(model.state_dict(), \"best_GPT_model_state_dict.pth\")\n",
    "        torch.save(optimizer.state_dict(), \"best_optimizer_state_dict.pth\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"last_GPT_model_state_dict.pth\")\n",
    "    torch.save(optimizer.state_dict(), \"last_optimizer_state_dict.pth\")\n",
    "\n",
    "    with open(f\"info_{n_epoch}.json\", \"w\", encoding=\"utf-8\") as file_obj:\n",
    "\n",
    "        info = {\n",
    "            \"message\": message,\n",
    "            \"train_losses\": train_losses,\n",
    "            \"validation_losses\": val_losses,\n",
    "            \"train_perplexities\": train_perplexities,\n",
    "            \"validation_perplexities\": val_perplexities\n",
    "        }\n",
    "\n",
    "        file_obj.write(json.dumps(info, indent=2))\n",
    "        \n",
    "# слишком долго"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 1294/1294 [01:54<00:00, 11.26it/s, loss=15, perplexity=3.43e+6]  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'epoch_train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-76d6cda81aa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepoch_val_losses\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmean_train_loss\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_train_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmean_val_loss\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_val_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epoch_train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "try: tqdm._instances.clear()\n",
    "except: pass\n",
    "\n",
    "epoch_val_losses   = evaluate(model, validation_loader, criterion)\n",
    "\n",
    "mean_train_loss    = np.mean(epoch_train_losses)\n",
    "mean_val_loss      = np.mean(epoch_val_losses)\n",
    "\n",
    "train_losses.append(epoch_train_losses)\n",
    "train_perplexities.append(np.exp(mean_train_loss))\n",
    "\n",
    "val_losses.append(epoch_val_losses)\n",
    "val_perplexities.append(np.exp(mean_val_loss))\n",
    "\n",
    "message = f\"Epoch: {n_epoch}\\n\"\n",
    "message += f\"Train: loss - {mean_train_loss:.4f} | perplexity - {train_perplexities[-1]:.3f}\\n\"\n",
    "message += f\"Validation: loss - {mean_val_loss: .4f} | perplexity - {val_perplexities[-1]:.3f}\"\n",
    "\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"last_GPT_model_state_dict.pth\")\n",
    "torch.save(optimizer.state_dict(), \"last_optimizer_state_dict.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
